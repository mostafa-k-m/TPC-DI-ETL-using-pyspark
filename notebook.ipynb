{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPC-DI ETL using pyspark\n",
    "\n",
    "please visit http://www.tpc.org/tpcdi/ for more information about TPC-DI and to get a copy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib64/jvm/jre-1.8.0-openjdk\"\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Project2 - ETL based on TPC-DI\") \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "We will start by defining functions to parse the xml file. We will read the xml file as an rdd then map those functions to said rdd to produce data frames. we had to create a separate function to handle each action type, A function to handle new customers, a function to handle updates, adding accounts and closing accounts.\n",
    "\n",
    "Each of these functions will produce a seperate rdd that we will later collect into dataframs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType, FloatType, DateType, TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`customer_parser` will handle new customers and will return all customer data and all account data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def customer_parser(rdd):\n",
    "    root = ET.fromstring(rdd[0])\n",
    "    records= []\n",
    "    for Action in root:\n",
    "        for Customer in Action:\n",
    "            ActionType = Action.attrib['ActionType']\n",
    "            if ActionType == 'NEW':\n",
    "                record = []\n",
    "                list_of_attributes = ['C_ID', 'C_TAX_ID', 'C_GNDR', 'C_TIER', 'C_DOB']\n",
    "                for attribute in list_of_attributes:\n",
    "                    try:\n",
    "                        record.append(Customer.attrib[attribute])\n",
    "                    except:\n",
    "                        record.append(None)\n",
    "                for Element in Customer:\n",
    "                    if Element.tag == 'ContactInfo':\n",
    "                        for Subelement in Element:\n",
    "                            if Subelement.tag[:-1] == 'C_PHONE_':\n",
    "                                phone_number = ''\n",
    "                                for Subsubelement in Subelement:\n",
    "                                    if isinstance(Subsubelement.text, str):                                \n",
    "                                        phone_number += Subsubelement.text + \" \"\n",
    "                                if len(phone_number)>1:\n",
    "                                    phone_number = phone_number[:-1]\n",
    "                                else:\n",
    "                                    phone_number = None\n",
    "                                record.append(phone_number)\n",
    "                            else:\n",
    "                                record.append(Subelement.text)\n",
    "                    elif Element.tag == 'Account':\n",
    "                        for attribute in Element.attrib.values():\n",
    "                            record.append(attribute)\n",
    "                        for Subelement in Element:\n",
    "                            record.append(Subelement.text)\n",
    "                    else:\n",
    "                        for Subelement in Element:\n",
    "                            record.append(Subelement.text)\n",
    "                records.append(record)\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`add_account_parser` will handle 'ADDACCT' action type and will return the account data and the customer's ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_account_parser(rdd):\n",
    "    root = ET.fromstring(rdd[0])\n",
    "    records= []\n",
    "    for Action in root:\n",
    "        for Customer in Action:\n",
    "            ActionType = Action.attrib['ActionType']\n",
    "            if ActionType == 'ADDACCT':\n",
    "                record = []\n",
    "                record.append(Customer.attrib['C_ID'])\n",
    "                for Element in Customer:\n",
    "                    if Element.tag == 'Account':\n",
    "                        for attribute in Element.attrib.values():\n",
    "                            record.append(attribute)\n",
    "                        for Subelement in Element:\n",
    "                            record.append(Subelement.text)\n",
    "                records.append(record)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`update_customer_parser` will handle 'UPDCUST' actions. We noticed that each update will have only the new fields. for example a customer could update their email but keep every thing else the same. our parser will return every field for each customer but will have None in fields that did not get updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_customer_parser(rdd):\n",
    "    root = ET.fromstring(rdd[0])\n",
    "    records= []\n",
    "    for Action in root:\n",
    "        for Customer in Action:\n",
    "            ActionType = Action.attrib['ActionType']\n",
    "            if ActionType == 'UPDCUST':\n",
    "                record = []\n",
    "                list_of_attributes = ['C_ID', 'C_TAX_ID', 'C_GNDR', 'C_TIER', 'C_DOB']\n",
    "                for attribute in list_of_attributes:\n",
    "                    try:\n",
    "                        record.append(Customer.attrib[attribute])\n",
    "                    except:\n",
    "                        record.append(None)\n",
    "                for Element in Customer:\n",
    "                    dict={\n",
    "                    \"C_L_NAME\":None,\n",
    "                    \"C_F_NAME\":None,\n",
    "                    \"C_M_NAME\":None,\n",
    "                    'C_ADLINE1':None,\n",
    "                    'C_ADLINE2':None,\n",
    "                    'C_ZIPCODE':None,\n",
    "                    'C_CITY':None,\n",
    "                    'C_STATE_PROV':None,\n",
    "                    'C_CTRY':None,\n",
    "                    'C_PRIM_EMAIL':None,\n",
    "                    'C_ALT_EMAIL':None,\n",
    "                    'C_PHONE_1':None,\n",
    "                    'C_PHONE_2':None,\n",
    "                    'C_PHONE_3':None,\n",
    "                    \"C_LCL_TX_ID\":None,\n",
    "                    \"C_NAT_TX_ID\":None\n",
    "                    }\n",
    "                    if Element.tag == 'ContactInfo':\n",
    "                        for Subelement in Element:\n",
    "                            if Subelement.tag[:-1] == 'C_PHONE_':\n",
    "                                phone_number = ''\n",
    "                                for Subsubelement in Subelement:\n",
    "                                    if isinstance(Subsubelement.text, str):                                \n",
    "                                        phone_number += Subsubelement.text + \" \"\n",
    "                                if len(phone_number)>1:\n",
    "                                    phone_number = phone_number[:-1]\n",
    "                                else:\n",
    "                                    phone_number = None\n",
    "                                dict[Subelement.tag] = phone_number\n",
    "                            else:\n",
    "                                dict[Subelement.tag] = Subelement.text\n",
    "                    elif Element.tag == 'Account':\n",
    "                        continue\n",
    "                    else:\n",
    "                        for Subelement in Element:\n",
    "                            dict[Subelement.tag] = Subelement.text\n",
    "                records.append(record+list(dict.values()))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`update_account_parser` will handle 'UPDACCT', no need to return None here because the account data is always complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_account_parser(rdd):\n",
    "    root = ET.fromstring(rdd[0])\n",
    "    records= []\n",
    "    for Action in root:\n",
    "        for Customer in Action:\n",
    "            ActionType = Action.attrib['ActionType']\n",
    "            if ActionType == 'UPDACCT':\n",
    "                record = []\n",
    "                record.append(Customer.attrib['C_ID'])\n",
    "                for Account in Customer:\n",
    "                    record.append(Account.attrib['CA_ID'])\n",
    "                    try:\n",
    "                        record.append(Account.attrib['CA_TAX_ST'])\n",
    "                    except:\n",
    "                        record.append(None)\n",
    "                        dict = {\n",
    "                        \"CA_B_ID\":None,\n",
    "                        \"CA_NAME\":None}\n",
    "                    for element in Account:\n",
    "                        dict[element.tag] = element.text\n",
    "                records.append(record+list(dict.values()))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider 'INACT' and 'CLOSEACCT' both 'INACT' for simplicity's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inactive_parser(rdd):\n",
    "    root = ET.fromstring(rdd[0])\n",
    "    records= []\n",
    "    for Action in root:\n",
    "        for Customer in Action:\n",
    "            ActionType = Action.attrib['ActionType']\n",
    "            if ActionType == 'INACT' or ActionType == 'CLOSEACCT':\n",
    "                records.append(Customer.attrib['C_ID'])\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Will read the xml file into an rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "file_rdd = spark.read.text('./Dataset/CustomerMgmt.xml', wholetext=True).rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will create `new_customer_records_rdd` by using `customer_parser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "new_customer_records_rdd = file_rdd.flatMap(customer_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`customer_parser` returns for each new customer, the customer details and their account details. we need to split the resulting dataframe to separate the customers' information from the accounts' information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "new_customer_schema = StructType([\n",
    "    StructField(\"C_ID\", StringType(), False),\n",
    "    StructField(\"C_TAX_ID\", StringType(), False),\n",
    "    StructField(\"C_GNDR\", StringType(), True),\n",
    "    StructField(\"C_TIER\", StringType(), True),\n",
    "    StructField(\"C_DOB\", StringType(), False),\n",
    "    StructField(\"C_L_NAME\", StringType(), False),\n",
    "    StructField(\"C_F_NAME\", StringType(), False),\n",
    "    StructField(\"C_M_NAME\", StringType(), True),\n",
    "    StructField(\"C_ADLINE1\", StringType(), False),\n",
    "    StructField(\"C_ADLINE2\", StringType(), True),\n",
    "    StructField(\"C_ZIPCODE\", StringType(), False),\n",
    "    StructField(\"C_CITY\", StringType(), False),\n",
    "    StructField(\"C_STATE_PROV\", StringType(), False),\n",
    "    StructField(\"C_CTRY\", StringType(), False),\n",
    "    StructField(\"C_PRIM_EMAIL\", StringType(), False),\n",
    "    StructField(\"C_ALT_EMAIL\", StringType(), True),\n",
    "    StructField(\"C_PHONE_1\", StringType(), True),\n",
    "    StructField(\"C_PHONE_2\", StringType(), True),\n",
    "    StructField(\"C_PHONE_3\", StringType(), True),\n",
    "    StructField(\"C_LCL_TX_ID\", StringType(), False),\n",
    "    StructField(\"C_NAT_TX_ID\", StringType(), False),\n",
    "    StructField(\"CA_ID\", StringType(), False),\n",
    "    StructField(\"CA_TAX_ST\", StringType(), False),\n",
    "    StructField(\"CA_B_ID\", StringType(), False),\n",
    "    StructField(\"CA_NAME\", StringType(), True)])\n",
    "customer_schema = StructType([\n",
    "    StructField(\"C_ID\", StringType(), True),\n",
    "    StructField(\"C_TAX_ID\", StringType(), True),\n",
    "    StructField(\"C_GNDR\", StringType(), True),\n",
    "    StructField(\"C_TIER\", StringType(), True),\n",
    "    StructField(\"C_DOB\", StringType(), True),\n",
    "    StructField(\"C_L_NAME\", StringType(), True),\n",
    "    StructField(\"C_F_NAME\", StringType(), True),\n",
    "    StructField(\"C_M_NAME\", StringType(), True),\n",
    "    StructField(\"C_ADLINE1\", StringType(), True),\n",
    "    StructField(\"C_ADLINE2\", StringType(), True),\n",
    "    StructField(\"C_ZIPCODE\", StringType(), True),\n",
    "    StructField(\"C_CITY\", StringType(), True),\n",
    "    StructField(\"C_STATE_PROV\", StringType(), True),\n",
    "    StructField(\"C_CTRY\", StringType(), True),\n",
    "    StructField(\"C_PRIM_EMAIL\", StringType(), True),\n",
    "    StructField(\"C_ALT_EMAIL\", StringType(), True),\n",
    "    StructField(\"C_PHONE_1\", StringType(), True),\n",
    "    StructField(\"C_PHONE_2\", StringType(), True),\n",
    "    StructField(\"C_PHONE_3\", StringType(), True),\n",
    "    StructField(\"C_LCL_TX_ID\", StringType(), True),\n",
    "    StructField(\"C_NAT_TX_ID\", StringType(), True)])\n",
    "account_schema = StructType([\n",
    "    StructField(\"C_ID\", StringType(), True),\n",
    "    StructField(\"CA_ID\", StringType(), True),\n",
    "    StructField(\"CA_TAX_ST\", StringType(), True),\n",
    "    StructField(\"CA_B_ID\", StringType(), True),\n",
    "    StructField(\"CA_NAME\", StringType(), True)])\n",
    "new_customer_df = new_customer_records_rdd.toDF(new_customer_schema).select(\"C_ID\", \"C_TAX_ID\", \"C_GNDR\", \"C_TIER\", \"C_DOB\", \"C_L_NAME\", \"C_F_NAME\", \"C_M_NAME\", \"C_ADLINE1\", \"C_ADLINE2\", \"C_ZIPCODE\", \"C_CITY\", \"C_STATE_PROV\", \"C_CTRY\", \"C_PRIM_EMAIL\", \"C_ALT_EMAIL\", \"C_PHONE_1\", \"C_PHONE_2\", \"C_PHONE_3\", \"C_LCL_TX_ID\", \"C_NAT_TX_ID\")\n",
    "new_account_df = new_customer_records_rdd.toDF(new_customer_schema).select(\"C_ID\", \"CA_ID\", \"CA_TAX_ST\", \"CA_B_ID\", \"CA_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two dataframes containing new customers' data and their accounts' data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------+------+----------+--------+--------+--------+--------------------+---------+---------+----------------+------------+--------------------+--------------------+--------------------+------------------+------------+---------+-----------+-----------+\n",
      "|C_ID|   C_TAX_ID|C_GNDR|C_TIER|     C_DOB|C_L_NAME|C_F_NAME|C_M_NAME|           C_ADLINE1|C_ADLINE2|C_ZIPCODE|          C_CITY|C_STATE_PROV|              C_CTRY|        C_PRIM_EMAIL|         C_ALT_EMAIL|         C_PHONE_1|   C_PHONE_2|C_PHONE_3|C_LCL_TX_ID|C_NAT_TX_ID|\n",
      "+----+-----------+------+------+----------+--------+--------+--------+--------------------+---------+---------+----------------+------------+--------------------+--------------------+--------------------+------------------+------------+---------+-----------+-----------+\n",
      "|   0|923-54-6498|     F|     3|1940-12-02| Joannis|   Adara|    null|     4779 Weller Way|     null|    92624|        Columbus|     Ontario|              Canada|Adara.Joannis@moo...|Adara.Joannis@gmx...|    1 872 523-8928|    492-3961|     null|        CA3|        YT3|\n",
      "|   1|645-68-9627|     F|     3|1982-12-17| Paperno|  Jirina|       P|   7216 Gates Avenue|     null|  H5K 1Q9|       Inglewood|          WI|United States of ...|Jirina.P.Paperno@...|Jirina.P.Paperno@...|          767-4707|        null|     null|        BC6|        NU7|\n",
      "|   2|332-28-3838|  null|     3|1994-06-08| McBryan|  Mariam|    null|   12566 Misty Upper|     null|    78220|        Berkeley|Saskatchewan|United States of ...|Mariam.McBryan@ag...|Mariam.McBryan@sh...|420 757-3642 61998|    811-7498|     null|        NY4|        IA1|\n",
      "|   3|472-49-1339|     B|     3|1944-09-01|    Adey| Robinia|       L|12513 Wesleyan Bo...|     null|  H2C 1Z2|            Hull|          AL|United States of ...|Robinia.L.Adey@12...|Robinia.L.Adey@ic...|    1 819 163-0774|777 787-1085|     null|        WI4|        MO1|\n",
      "|   4|700-39-4024|     m|  null|1999-09-22| Haubert|    Lulu|    null| 6066 Fillmore Lower|     null|    10044|Rancho Cucamonga|          OR|United States of ...|Lulu.Haubert@buff...|                null|          734-4072|    713-2893|     null|        ON4|        MB7|\n",
      "+----+-----------+------+------+----------+--------+--------+--------+--------------------+---------+---------+----------------+------------+--------------------+--------------------+--------------------+------------------+------------+---------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customer_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+-------+--------------------+\n",
      "|C_ID|CA_ID|CA_TAX_ST|CA_B_ID|             CA_NAME|\n",
      "+----+-----+---------+-------+--------------------+\n",
      "|   0|    0|        1|  17713|CJlmMuFyibKOmKLHI...|\n",
      "|   1|    1|        2|    615|BbxTgVGOlgyrYtVRj...|\n",
      "|   2|    2|        1|   3927|IGzIDNTTRUDKwGaoV...|\n",
      "|   3|    3|        1|   6256|ZHXwHtCcLZqdWhWOP...|\n",
      "|   4|    4|        1|   3412|mzlYZlTIDmOGuKQHO...|\n",
      "+----+-----+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_account_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create `add_account_records_rdd` using `add_account_parser` and will create another dataframes containing accounts that existing customers added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+-------+--------------------+\n",
      "|C_ID|CA_ID|CA_TAX_ST|CA_B_ID|             CA_NAME|\n",
      "+----+-----+---------+-------+--------------------+\n",
      "|  88|  125|        2|  12126|WUIiLVBcUKKmgobPO...|\n",
      "|  54|  126|        1|  15244|JEddDkBzL R NXaer...|\n",
      "|  20|  127|        0|  12314|fFWYxTIiUmlHCHaCc...|\n",
      "|  21|  128|        1|  25910|PDQySQaONlBUACNtV...|\n",
      "|  77|  129|        1|  43888|ASPUxCpSHDPGGNQva...|\n",
      "+----+-----+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_account_records_rdd = file_rdd.flatMap(add_account_parser)\n",
    "add_account_df = add_account_records_rdd.toDF(account_schema)\n",
    "add_account_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create `updated_account_rdd` with `update_account_parser` and create a dataframe that contains all the acounts that have been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "updated_account_rdd = file_rdd.flatMap(update_account_parser)\n",
    "updated_account_df = updated_account_rdd.toDF(account_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to collect all the accounts in one dataframe we will do the following:\n",
    "- We concatenate `new_account_df` and `add_account_df`, to get all the initial accounts data in one dataframe.\n",
    "- We will do a left anti join between the new accounts and the updated accounts to get only the accounts that have not been updated.\n",
    "- Then we will concatenate the result with the accounts that have been updated. the resulting dataframe will have all up to date account data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accounts = new_account_df.union(add_account_df).join(updated_account_df, on=['C_ID','CA_ID'], how='left_anti').union(updated_account_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally for the accounts, we will populate the `CA_ST_ID` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-------+--------------------+--------+\n",
      "| C_ID|CA_ID|CA_TAX_ST|CA_B_ID|             CA_NAME|CA_ST_ID|\n",
      "+-----+-----+---------+-------+--------------------+--------+\n",
      "|   10| 3429|        1|   4984|NvnqmafKEeRraHJlD...|    INAC|\n",
      "|10284|20469|        0|  30262|WSrAJPnvZzbENxGPc...|    ACTV|\n",
      "|10472|20832|        1|   7082|GxHMKBqZhsFTwZxrB...|    ACTV|\n",
      "|  106|  916|        1|  27782|fXyDCcGSMkKqkcAJD...|    INAC|\n",
      "|11165|22225|        1|  12877|i HGYvIGvIsbtW KO...|    ACTV|\n",
      "+-----+-----+---------+-------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inactive_accounts = file_rdd.flatMap(inactive_parser)\n",
    "inact_list = inactive_accounts.collect()\n",
    "inact_func = udf(lambda x: 'INAC' if str(x) in inact_list else 'ACTV')\n",
    "\n",
    "Accounts = Accounts.withColumn('CA_ST_ID', inact_func(Accounts.C_ID))\n",
    "Accounts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to customers, we will create a dataframe that contains all the customers who updated their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+------+-----+--------+--------+--------+---------+---------+---------+------+------------+------+--------------------+--------------------+--------------+--------------+------------------+-----------+-----------+\n",
      "|C_ID|C_TAX_ID|C_GNDR|C_TIER|C_DOB|C_L_NAME|C_F_NAME|C_M_NAME|C_ADLINE1|C_ADLINE2|C_ZIPCODE|C_CITY|C_STATE_PROV|C_CTRY|        C_PRIM_EMAIL|         C_ALT_EMAIL|     C_PHONE_1|     C_PHONE_2|         C_PHONE_3|C_LCL_TX_ID|C_NAT_TX_ID|\n",
      "+----+--------+------+------+-----+--------+--------+--------+---------+---------+---------+------+------------+------+--------------------+--------------------+--------------+--------------+------------------+-----------+-----------+\n",
      "|  69|    null|  null|     2| null|    null|    null|    null|     null|     null|     null|  null|        null|  null|Venus.DiLoreto@ip...|                null|1 889 662-1131|      505-9373|              null|       null|       null|\n",
      "|   7|    null|  null|     3| null|    null|    null|    null|     null|     null|     null|  null|        null|  null|Riyad.Ayukawa@eur...|Riyad.Ayukawa@Sof...|      837-8927|672-0894 74696|    1 893 482-1103|       null|       null|\n",
      "|  35|    null|  null|     1| null|    null|    null|    null|     null|     null|     null|  null|        null|  null|                null|                null|  790 829-6136|          null|              null|       null|       null|\n",
      "|   0|    null|  null|  null| null|    null|    null|    null|     null|     null|     null|  null|        null|  null|Adara.Joannis@gma...|                null|  357 423-9191|  270 141-3475|421 277-2023 59348|       null|       null|\n",
      "|  28|    null|  null|     3| null|    null|    null|    null|     null|     null|     null|  null|        null|  null|  Dido.Harris@gmx.it|                null|      882-2241|  707 384-6361|              null|       null|       null|\n",
      "+----+--------+------+------+-----+--------+--------+--------+---------+---------+---------+------+------------+------+--------------------+--------------------+--------------+--------------+------------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "update_customer_rdd = file_rdd.flatMap(update_customer_parser)\n",
    "update_customer_df = update_customer_rdd.toDF(customer_schema)\n",
    "update_customer_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a left anti join between `new_customer_df` and `update_customer_df` to get all the customers whose information did not get updated in one dataframe. We will then do an inner join between `new_customer_df` and `update_customer_df`to get all customers whose information has been updated. The resulting datafram will have, for each customer, one value for ID and two values for each other field. one coming from the data before the update and one from after. The data from after the update is incomplete and will contain null values if a certain feild did not get updated.\n",
    "\n",
    "We will rename the second dataframes columns for clarity by appending '_pdate' to the updated columns. for example \"phone1\" and \"phone1_update\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "customers_not_updated = new_customer_df.join(update_customer_df, on=['C_ID'], how='left_anti')\n",
    "customers_updated = new_customer_df.join(update_customer_df, on=['C_ID'], how='inner')\n",
    "columns = []\n",
    "for index, column in enumerate(customers_updated.columns):\n",
    "    if index <= 20:\n",
    "        columns.append(column)\n",
    "    else:\n",
    "        columns.append(column+'_update')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to iterate over each row to check if each field has been updated (if the new value is not null) and replace the old value with the new value. to achieve this we will convert the dataframe back to rdd then use `customer_updater` to insert the updated values and we will get a dataframe that will have the up to date data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+------+----------+---------+--------+--------+--------------------+---------+---------+------------+------------+--------------------+--------------------+--------------------+--------------+------------+---------+-----------+-----------+\n",
      "| C_ID|   C_TAX_ID|C_GNDR|C_TIER|     C_DOB| C_L_NAME|C_F_NAME|C_M_NAME|           C_ADLINE1|C_ADLINE2|C_ZIPCODE|      C_CITY|C_STATE_PROV|              C_CTRY|        C_PRIM_EMAIL|         C_ALT_EMAIL|     C_PHONE_1|   C_PHONE_2|C_PHONE_3|C_LCL_TX_ID|C_NAT_TX_ID|\n",
      "+-----+-----------+------+------+----------+---------+--------+--------+--------------------+---------+---------+------------+------------+--------------------+--------------------+--------------------+--------------+------------+---------+-----------+-----------+\n",
      "|10436|925-79-3935|  null|     3|2005-01-15|   Hachey|  Sarath|    null|196 Bellaire Cres...|     null|    19244|Fort Collins|          NM|United States of ...|Sarath.Hachey@icq...|Sarath.Hachey@gmx...|743-0141 32615|957 649-7453| 769-5940|        OH8|       MT10|\n",
      "|11078|186-47-5873|     f|     3|1946-04-15|   Namiki|   Robin|       M|23710 Amsterdam B...|     null|  E7O 1M3|  Pittsburgh|          AL|United States of ...|Robin.M.Namiki@ma...|Robin.M.Namiki@hu...|      464-1326|    722-1040|     null|        OK6|        AR6|\n",
      "|11078|186-47-5873|     f|     3|1946-04-15|   Namiki|   Robin|       M|23710 Amsterdam B...|     null|  E7O 1M3|  Pittsburgh|          AL|United States of ...|Robin.M.Namiki@en...|Robin.M.Namiki@my...|      444-8396|    722-1040|     null|        OK6|        AR6|\n",
      "| 1436|604-00-3391|  null|     3|2014-08-19|    Hadel|Surinder|       E|   15079 Decatur Rue|     null|    80902|  Pittsburgh|          MT|              Canada|Surinder.E.Hadel@...|Surinder.E.Hadel@...|      349-3359|    704-1650|     null|        OK5|        AR5|\n",
      "| 2088|241-27-2005|  null|     2|1939-09-10|Bessuille|    Sriv|       I|  17261 Alpine Upper|     null|  B1C 1X8| West Valley|          FL|              Canada|Sriv.I.Bessuille@...|Sriv.I.Bessuille@...|      698-6703|    173-8642|     null|        CA3|        SK4|\n",
      "+-----+-----------+------+------+----------+---------+--------+--------+--------------------+---------+---------+------------+------------+--------------------+--------------------+--------------------+--------------+------------+---------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_updated = customers_updated.toDF(*columns).rdd\n",
    "def customer_updater(row):\n",
    "    new_row= [row.C_ID]\n",
    "    for column in columns:\n",
    "        if column != 'C_ID' and (not '_update' in column):\n",
    "            if not getattr(row,column+'_update') is None:\n",
    "                new_row.append(getattr(row,column+'_update'))\n",
    "            else:\n",
    "                new_row.append(getattr(row,column))\n",
    "    return new_row\n",
    "customers_updated = customers_updated.map(customer_updater).toDF(customer_schema)\n",
    "customers_updated.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will concatenate the dataframe containing customers who did not get updated and the dataframe containing customers who did get updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+------+----------+--------+--------+--------+--------------------+---------+---------+---------------+--------------------+--------------------+--------------------+--------------------+------------------+------------+--------------+-----------+-----------+\n",
      "| C_ID|   C_TAX_ID|C_GNDR|C_TIER|     C_DOB|C_L_NAME|C_F_NAME|C_M_NAME|           C_ADLINE1|C_ADLINE2|C_ZIPCODE|         C_CITY|        C_STATE_PROV|              C_CTRY|        C_PRIM_EMAIL|         C_ALT_EMAIL|         C_PHONE_1|   C_PHONE_2|     C_PHONE_3|C_LCL_TX_ID|C_NAT_TX_ID|\n",
      "+-----+-----------+------+------+----------+--------+--------+--------+--------------------+---------+---------+---------------+--------------------+--------------------+--------------------+--------------------+------------------+------------+--------------+-----------+-----------+\n",
      "|10096|214-25-1030|  null|     3|1997-09-15|  Polder|    Kyla|    null|    15031 Wood South|     null|    29409|          Omaha|                  CA|United States of ...|  Kyla.Polder@gmx.hk|                null|      533 560-6464|950 140-4160|1 217 452-4683|        OK4|        AR5|\n",
      "|10351|461-07-0288|  null|     3|1981-04-02|   Perez|Germaine|       J|    24160 Star Drive|     null|    66624| San Bernardino|Prince Edward Island|United States of ...|Germaine.J.Perez@...|                null|          084-5037|        null|          null|        IA5|        MT9|\n",
      "| 1090|668-12-9960|  null|     2|2011-12-08| Grisoni|   Steve|    null|22820 Wilshire Bo...|     null|    33108|Fort Lauderdale|                  NC|United States of ...|Steve.Grisoni@sht...|Steve.Grisoni@gmx.sg|          200-8103|530 132-0772|          null|        MT3|        WY1|\n",
      "|11332|460-09-5021|     f|     3|1974-03-16|  Cawley|  Dulcie|       K|4953 Williams Bou...|     null|    93792| Corpus Christi|                  SC|United States of ...|Dulcie.K.Cawley@p...|Dulcie.K.Cawley@l...|421 969-8302 70924|        null|1 324 726-9321|        CA3|        MO6|\n",
      "|11563|972-84-0885|     M|     3|1982-07-02|   Adcox|     Viv|    null|        3020 Fox Rue|     null|    33613|          Sandy|                  OK|United States of ...|Viv.Adcox@soodoni...|Viv.Adcox@letterb...|    1 536 315-5937|        null|          null|        NT8|        CA3|\n",
      "+-----+-----------+------+------+----------+--------+--------+--------+--------------------+---------+---------+---------------+--------------------+--------------------+--------------------+--------------------+------------------+------------+--------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Customers = customers_not_updated.union(customers_updated)\n",
    "Customers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+\n",
      "|TX_ID|             TX_NAME|TX_RATE|\n",
      "+-----+--------------------+-------+\n",
      "|  US1|U.S. Income Tax B...|   0.15|\n",
      "|  US2|U.S. Income Tax B...|  0.275|\n",
      "|  US3|U.S. Income Tax B...|  0.305|\n",
      "|  US4|U.S. Income Tax B...|  0.355|\n",
      "|  US5|U.S. Income Tax B...|  0.391|\n",
      "+-----+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " schema_TaxRate = StructType([\n",
    "    StructField(\"TX_ID\", StringType(), False),\n",
    "    StructField(\"TX_NAME\", StringType(), False),\n",
    "    StructField(\"TX_RATE\", FloatType(), False)])\n",
    "\n",
    "df_TaxRate = spark.read\\\n",
    "            .format(\"csv\")\\\n",
    "            .schema(schema_TaxRate)\\\n",
    "            .option(\"header\", \"false\")\\\n",
    "            .option(\"sep\", \"|\")\\\n",
    "            .load(\"./Dataset/TaxRate.txt\")\n",
    "df_TaxRate.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+-------------+------+--------------------+------------+----------+---------------+-----+--------------------+--------------+------+----------+--------------+-------------+----+------------+-------------+--------------------+-----------------+--------+\n",
      "|AgencyID|LastName|FirstName|MiddleInitial|Gender|        AddressLine1|AddressLine2|PostalCode|           City|State|             Country|         Phone|Income|NumberCars|NumberChildren|MaritalStatus| Age|CreditRating|OwnOrRentFlag|            Employer|NumberCreditCards|NetWorth|\n",
      "+--------+--------+---------+-------------+------+--------------------+------------+----------+---------------+-----+--------------------+--------------+------+----------+--------------+-------------+----+------------+-------------+--------------------+-----------------+--------+\n",
      "|    KOZ0|  KOZIOL|  Mahmood|         null|  null|17886 st. phillip...|        null|   H6b 1w1|       St. Paul|   TN|              Canada|1-712-522-6088|368776|      null|             3|            W|  20|         760|            O|             Brink's|             null| 1058868|\n",
      "|    DIS1|DISCOVER|     ROEL|            J|  null|5539 carrington west|        null|     43602|       Columbia|   CO|United States of ...|1-626-426-4298|177967|         5|             1|            U|   3|         555|            U|                null|                6| 1988185|\n",
      "|    rom2|  romano|    brear|         null|     m|13031 lendon cres...|    apt. 180|   E7n 1p8|North Las Vegas|   WY|United States of ...|1-524-787-8784|321772|         2|             1|            S|null|         566|            O|                null|                6| 3673128|\n",
      "|    SCH3|SCHINKEL|      Bev|         null|  null|   22594 reagan park|        null|     13222|       Victoria|   MT|United States of ...|1-741-997-1688| 25449|         2|             1|            W|  77|        null|            O|Air Products & Ch...|                3| 2005895|\n",
      "|    BIS4|   BISCH|  analise|         null|     M|4833 baltic boule...|        null|   h5i 1o4|        Detroit|   MT|United States of ...|1-002-194-1991|166567|         0|             3|            M|  21|         815|            O|             Oshkosh|                4|  624736|\n",
      "+--------+--------+---------+-------------+------+--------------------+------------+----------+---------------+-----+--------------------+--------------+------+----------+--------------+-------------+----+------------+-------------+--------------------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_Prospect = StructType([\n",
    "    StructField(\"AgencyID\", StringType(), False),\n",
    "    StructField(\"LastName\", StringType(), False),\n",
    "    StructField(\"FirstName\", StringType(), False),\n",
    "    StructField(\"MiddleInitial\", StringType(), False),\n",
    "    StructField(\"Gender\", StringType(), False),\n",
    "    StructField(\"AddressLine1\", StringType(), False),\n",
    "    StructField(\"AddressLine2\", StringType(), False),\n",
    "    StructField(\"PostalCode\", StringType(), False),\n",
    "    StructField(\"City\", StringType(), False),\n",
    "    StructField(\"State\", StringType(), False),\n",
    "    StructField(\"Country\", StringType(), False),\n",
    "    StructField(\"Phone\", StringType(), False),\n",
    "    StructField(\"Income\", IntegerType(), False),\n",
    "    StructField(\"NumberCars\", IntegerType(), False),\n",
    "    StructField(\"NumberChildren\", IntegerType(), False),\n",
    "    StructField(\"MaritalStatus\", StringType(), False),\n",
    "    StructField(\"Age\", IntegerType(), False),\n",
    "    StructField(\"CreditRating\", IntegerType(), False),\n",
    "    StructField(\"OwnOrRentFlag\", StringType(), False),\n",
    "    StructField(\"Employer\", StringType(), False),\n",
    "    StructField(\"NumberCreditCards\", IntegerType(), False),\n",
    "    StructField(\"NetWorth\", IntegerType(), False)])\n",
    "\n",
    "df_Prospect = spark.read\\\n",
    "            .format(\"csv\")\\\n",
    "            .schema(schema_Prospect)\\\n",
    "            .option(\"header\", \"false\")\\\n",
    "            .option(\"sep\", \",\")\\\n",
    "            .load(\"./Dataset/Prospect.csv\")\n",
    "df_Prospect.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "df_TaxRate_broad = broadcast(df_TaxRate)\n",
    "df_TaxRate_broad.createOrReplaceTempView(\"TaxRate_broad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_Prospect_broad = broadcast(df_Prospect)\n",
    "df_Prospect_broad.createOrReplaceTempView(\"Prospect_broad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "schema_Account = StructType([\n",
    "    StructField(\"CDC_FLAG\", StringType(), False),\n",
    "    StructField(\"CDC_DSN\", IntegerType(), True),\n",
    "    StructField(\"CA_ID\", IntegerType(), True),\n",
    "    StructField(\"CA_B_ID\", IntegerType(), True),\n",
    "    StructField(\"CA_C_ID\", IntegerType(), True),\n",
    "    StructField(\"CA_NAME\", StringType(), False),\n",
    "    StructField(\"CA_TAX_ST\", IntegerType(), True),\n",
    "    StructField(\"CA_ST_ID\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_StatusType = spark.read\\\n",
    "            .format(\"csv\")\\\n",
    "            .schema('ST_ID string, ST_NAME string')\\\n",
    "            .option(\"header\", \"false\")\\\n",
    "            .option(\"sep\", \"|\")\\\n",
    "            .load(\"./Dataset/StatusType.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|ST_ID|  ST_NAME|\n",
      "+-----+---------+\n",
      "| ACTV|   Active|\n",
      "| CMPT|Completed|\n",
      "| CNCL| Canceled|\n",
      "| PNDG|  Pending|\n",
      "| SBMT|Submitted|\n",
      "| INAC| Inactive|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_StatusType.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_StatusType_broad = broadcast(df_StatusType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "Accounts.createOrReplaceTempView(\"accounts\")\n",
    "df_StatusType_broad.createOrReplaceTempView(\"statusType_broad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dimAccount = spark.sql(\"\\\n",
    "                       Select CA_ID as AccountID,\\\n",
    "                       C_ID as CustomerID,\\\n",
    "                       ST_NAME as Status,\\\n",
    "                       CA_NAME as AccountDesc,\\\n",
    "                       CA_TAX_ST as TaxStatus,\\\n",
    "                       CAST('True' as BOOLEAN) as IsCurrent,\\\n",
    "                       CAST('1' as INT) as BatchID,\\\n",
    "                       to_date('2015-01-01', 'yyyy-MM-dd') as EffectiveDate,\\\n",
    "                       to_date('9999-12-31', 'yyyy-MM-dd') as EndDate\\\n",
    "                       From accounts join statusType_broad on accounts.CA_ST_ID = statusType_broad.ST_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+--------------------+---------+---------+-------+-------------+----------+\n",
      "|AccountID|CustomerID|  Status|         AccountDesc|TaxStatus|IsCurrent|BatchID|EffectiveDate|   EndDate|\n",
      "+---------+----------+--------+--------------------+---------+---------+-------+-------------+----------+\n",
      "|     3429|        10|Inactive|NvnqmafKEeRraHJlD...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    20469|     10284|  Active|WSrAJPnvZzbENxGPc...|        0|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    20832|     10472|  Active|GxHMKBqZhsFTwZxrB...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|      916|       106|Inactive|fXyDCcGSMkKqkcAJD...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    22225|     11165|  Active|i HGYvIGvIsbtW KO...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    28436|     11167|  Active|WmgHiXrLf kNTUXSI...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    25613|     11338|  Active|ZFqDhUqNLjCjSdCsd...|        2|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    22638|     11368|  Active|fUkAPQJeRLJEYsswr...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    12519|      1147|  Active|ciHrvUfyCUpsAqFHm...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "|    22869|     11494|  Active|FHaCaIweDYOreJPk ...|        1|     true|      1|   2015-01-01|9999-12-31|\n",
      "+---------+----------+--------+--------------------+---------+---------+-------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimAccount.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AccountID: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- AccountDesc: string (nullable = true)\n",
      " |-- TaxStatus: string (nullable = true)\n",
      " |-- IsCurrent: boolean (nullable = true)\n",
      " |-- BatchID: integer (nullable = true)\n",
      " |-- EffectiveDate: date (nullable = true)\n",
      " |-- EndDate: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimAccount.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "Customers.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dimCustomer = spark.sql(\"\\\n",
    "                       Select c.C_ID as CustomerID,\\\n",
    "                       C_TAX_ID as TaxID,\\\n",
    "                       C_L_NAME as LastName,\\\n",
    "                       C_F_NAME as FirstName,\\\n",
    "                       C_M_NAME as MiddleInitial,\\\n",
    "                       C_GNDR as Gender,\\\n",
    "                       C_TIER as Tier,\\\n",
    "                       C_DOB as DOB,\\\n",
    "                       C_ADLINE1 as AddressLine1,\\\n",
    "                       C_ADLINE2 as AddressLine2,\\\n",
    "                       C_ZIPCODE as PostalCode,\\\n",
    "                       C_CITY as City,\\\n",
    "                       C_STATE_PROV as StateProv,\\\n",
    "                       C_CTRY as Country,\\\n",
    "                       C_PHONE_1 as Phone1,\\\n",
    "                       C_PHONE_2 as Phone2,\\\n",
    "                       C_PHONE_3 as Phone3,\\\n",
    "                       C_PRIM_EMAIL as Email1,\\\n",
    "                       C_ALT_EMAIL as Email2,\\\n",
    "                       NAT.TX_NAME as NationalTaxRateDesc,\\\n",
    "                       NAT.TX_RATE as NationalTaxRate,\\\n",
    "                       LCL.TX_NAME as LocalTaxRateDesc,\\\n",
    "                       LCL.TX_RATE as LocalTaxRate,\\\n",
    "                       AgencyID as AgencyID,\\\n",
    "                       CreditRating as CreditRating,\\\n",
    "                       NetWorth as NetWorth,\\\n",
    "                        COALESCE(CASE \\\n",
    "                            WHEN NetWorth > 1000000 THEN 'HighValue+' \\\n",
    "                            ELSE NULL \\\n",
    "                        END,\\\n",
    "                       CASE \\\n",
    "                            WHEN NumberChildren > 3 THEN 'Expenses+' \\\n",
    "                            WHEN NumberCreditCards > 5 THEN 'Expenses+'\\\n",
    "                            ELSE NULL \\\n",
    "                        END,\\\n",
    "                       CASE \\\n",
    "                            WHEN Age > 45 THEN 'Boomer+' \\\n",
    "                            ELSE NULL \\\n",
    "                        END,\\\n",
    "                       CASE \\\n",
    "                            WHEN Income < 50000 THEN 'MoneyAlert+' \\\n",
    "                            WHEN CreditRating < 600 THEN 'MoneyAlert+' \\\n",
    "                            WHEN NetWorth < 100000 THEN 'MoneyAlert+' \\\n",
    "                            ELSE Null \\\n",
    "                        END,\\\n",
    "                       CASE \\\n",
    "                            WHEN NumberCars > 3 THEN 'Spender+' \\\n",
    "                            WHEN NumberCreditCards > 7 THEN 'Spender+' \\\n",
    "                            ELSE Null \\\n",
    "                        END,\\\n",
    "                       CASE \\\n",
    "                            WHEN Age < 25 THEN 'Inherited' \\\n",
    "                            WHEN NetWorth > 100000 THEN 'Inherited' \\\n",
    "                            ELSE Null \\\n",
    "                        END) as MarketingNameplate,\\\n",
    "                       CAST('True' as BOOLEAN) as IsCurrent,\\\n",
    "                       CAST('1' as INT) as BatchID,\\\n",
    "                       to_date('2015-01-01', 'yyyy-MM-dd') as EffectiveDate,\\\n",
    "                       to_date('9999-12-31', 'yyyy-MM-dd') as EndDate\\\n",
    "                       From customers as c \\\n",
    "                       left join TaxRate_broad as NAT on c.C_NAT_TX_ID = NAT.TX_ID\\\n",
    "                       left join TaxRate_broad as LCL on c.C_LCL_TX_ID = LCL.TX_ID\\\n",
    "                       left join Prospect_broad as p on (c.C_L_NAME = p.LastName and c.C_F_NAME = p.FirstName and c.C_ADLINE1 = p.AddressLine1 and c.C_ADLINE2 =  p.AddressLine2 and c.C_ZIPCODE = p.PostalCode)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[AgencyID: string, LastName: string, FirstName: string, MiddleInitial: string, Gender: string, AddressLine1: string, AddressLine2: string, PostalCode: string, City: string, State: string, Country: string, Phone: string, Income: int, NumberCars: int, NumberChildren: int, MaritalStatus: string, Age: int, CreditRating: int, OwnOrRentFlag: string, Employer: string, NumberCreditCards: int, NetWorth: int]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd.unpersist()\n",
    "new_customer_records_rdd.unpersist()\n",
    "new_customer_df.unpersist()\n",
    "new_account_df.unpersist()\n",
    "add_account_records_rdd.unpersist()\n",
    "add_account_df.unpersist()\n",
    "Accounts.unpersist()\n",
    "inactive_accounts.unpersist()\n",
    "update_customer_rdd.unpersist()\n",
    "update_customer_df.unpersist()\n",
    "customers_not_updated.unpersist()\n",
    "customers_updated.unpersist()\n",
    "Customers.unpersist()\n",
    "df_TaxRate.unpersist()\n",
    "df_Prospect.unpersist()\n",
    "df_TaxRate_broad.unpersist()\n",
    "df_Prospect_broad.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+---------+-------------+------+----+----------+--------------------+------------+----------+---------------+--------------------+--------------------+------------------+------------+--------------+--------------------+--------------------+--------------------+---------------+--------------------+------------+--------+------------+--------+------------------+---------+-------+-------------+----------+--------+\n",
      "|CustomerID|      TaxID|LastName|FirstName|MiddleInitial|Gender|Tier|       DOB|        AddressLine1|AddressLine2|PostalCode|           City|           StateProv|             Country|            Phone1|      Phone2|        Phone3|              Email1|              Email2| NationalTaxRateDesc|NationalTaxRate|    LocalTaxRateDesc|LocalTaxRate|AgencyID|CreditRating|NetWorth|MarketingNameplate|IsCurrent|BatchID|EffectiveDate|   EndDate|  Status|\n",
      "+----------+-----------+--------+---------+-------------+------+----+----------+--------------------+------------+----------+---------------+--------------------+--------------------+------------------+------------+--------------+--------------------+--------------------+--------------------+---------------+--------------------+------------+--------+------------+--------+------------------+---------+-------+-------------+----------+--------+\n",
      "|     10096|214-25-1030|  Polder|     Kyla|         null|  null|   3|1997-09-15|    15031 Wood South|        null|     29409|          Omaha|                  CA|United States of ...|      533 560-6464|950 140-4160|1 217 452-4683|  Kyla.Polder@gmx.hk|                null|Arkansas Tax for ...|         0.0567|Oklahoma Income T...|      0.0318|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|     10351|461-07-0288|   Perez| Germaine|            J|  null|   3|1981-04-02|    24160 Star Drive|        null|     66624| San Bernardino|Prince Edward Island|United States of ...|          084-5037|        null|          null|Germaine.J.Perez@...|                null|Montana Income Ta...|            0.1|Iowa Income Tax f...|      0.0467|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|      1090|668-12-9960| Grisoni|    Steve|         null|  null|   2|2011-12-08|22820 Wilshire Bo...|        null|     33108|Fort Lauderdale|                  NC|United States of ...|          200-8103|530 132-0772|          null|Steve.Grisoni@sht...|Steve.Grisoni@gmx.sg|Wyoming Income Ta...|            0.0|Montana Income Ta...|        0.04|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|Inactive|\n",
      "|     11332|460-09-5021|  Cawley|   Dulcie|            K|     f|   3|1974-03-16|4953 Williams Bou...|        null|     93792| Corpus Christi|                  SC|United States of ...|421 969-8302 70924|        null|1 324 726-9321|Dulcie.K.Cawley@p...|Dulcie.K.Cawley@l...|Missouri Income T...|           0.04|California Tax fo...|      0.0432|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|     11563|972-84-0885|   Adcox|      Viv|         null|     M|   3|1982-07-02|        3020 Fox Rue|        null|     33613|          Sandy|                  OK|United States of ...|    1 536 315-5937|        null|          null|Viv.Adcox@soodoni...|Viv.Adcox@letterb...|California Tax fo...|         0.0432|Northwest Territo...|       0.434|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|      1159|502-65-7980|  Widdis|   Jennee|            S|  null|   2|2017-02-19|    15031 Wood South|        null|     53714|        Madison|                  HI|United States of ...|      575 525-5498|760 164-1499|1 640 959-7333|Jennee.S.Widdis@s...|                null|North Dakota Inco...|         0.0667|District of Colum...|       0.095|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|     11722|580-43-0559|  Senese|  Kristen|            F|  null|null|1986-05-18|19570 Winter Park...|    Apt. 602|     73132|       Victoria|            Manitoba|United States of ...|589 643-8343 21134|        null|          null|Kristen.F.Senese@...|Kristen.F.Senese@...|Utah Income Tax f...|           0.07|Nova Scotia Incom...|      0.3077|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|     11888|774-76-4757|   Mader|   Ronnie|         null|  null|   3|1935-05-15|      5317 Drew East|     Apt. 34|     72909|     Scottsdale|                  VT|United States of ...|      992 459-1649|    836-3228|          null|Ronnie.Mader@hush...|                null|Saskatchewan Inco...|           0.38|Iowa Income Tax f...|      0.0252|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "|     12394|258-56-5579|    Nass|   Mehmud|         null|  null|   3|1958-12-10| 22083 Crossus Lower|        null|   M5B 1Y5|         Pomona|                  VA|              Canada|          359-0824|        null|          null|Mehmud.Nass@kify.net|                null|Idaho Income Tax ...|         0.0466|Illinois Income T...|        0.03|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|Inactive|\n",
      "|     12529|662-49-8573| Szamosi|   Pearla|            A|  null|   1|1941-03-27|   10314 Presido Way|        null|     77126|         Nashua|                  AR|              Canada|    695-6853 06892|809 123-6709|          null|Pearla.A.Szamosi@...|                null|New Brunswick Inc...|           0.16|Kentucky Income T...|        0.03|    null|        null|    null|              null|     true|      1|   2015-01-01|9999-12-31|  Active|\n",
      "+----------+-----------+--------+---------+-------------+------+----+----------+--------------------+------------+----------+---------------+--------------------+--------------------+------------------+------------+--------------+--------------------+--------------------+--------------------+---------------+--------------------+------------+--------+------------+--------+------------------+---------+-------+-------------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inact_func = udf(lambda x: 'Inactive' if str(x) in inact_list else 'Active')\n",
    "\n",
    "dimCustomer = dimCustomer.withColumn('Status', inact_func(dimCustomer.CustomerID))\n",
    "dimCustomer.show(10)\n",
    "dimCustomer.createOrReplaceTempView(\"tbldimCustomer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "schema_Date = StructType([\n",
    "    StructField(\"SK_DateID\", IntegerType(), False),\n",
    "    StructField(\"DateValue\", StringType(), False),\n",
    "    StructField(\"DateDesc\", StringType(), False),\n",
    "    StructField(\"CalendarYearID\", IntegerType(), False),\n",
    "    StructField(\"CalendarYearDesc\", StringType(), False),\n",
    "    StructField(\"CalendarQtrID\", IntegerType(), False),\n",
    "    StructField(\"CalendarQtrDesc\", StringType(), False),\n",
    "    \n",
    "    StructField(\"CalendarMonthID\", IntegerType(), False),\n",
    "    StructField(\"CalendarMonthDesc\", StringType(), False),\n",
    "    StructField(\"CalendarWeekID\", IntegerType(), False),\n",
    "    StructField(\"CalendarWeekDesc\", StringType(), False),\n",
    "    \n",
    "    StructField(\"DayOfWeekNum\", IntegerType(), False),\n",
    "    StructField(\"DayOfWeekDesc\", StringType(), False),\n",
    "    StructField(\"FiscalYearID\", IntegerType(), False),\n",
    "    StructField(\"FiscalYearDesc\", StringType(), False),\n",
    "    \n",
    "    StructField(\"FiscalQtrID\", IntegerType(), False),\n",
    "    StructField(\"FiscalQtrDesc\", StringType(), False),\n",
    "    \n",
    "    StructField(\"HolidayFlag\", BooleanType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_Date = spark.read\\\n",
    "            .format(\"csv\")\\\n",
    "            .schema(schema_Date)\\\n",
    "            .option(\"header\", \"false\")\\\n",
    "            .option(\"sep\", \"|\")\\\n",
    "            .load(\"./Dataset/Date.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+--------------+----------------+-------------+---------------+---------------+-----------------+--------------+----------------+------------+-------------+------------+--------------+-----------+-------------+-----------+\n",
      "|SK_DateID| DateValue|        DateDesc|CalendarYearID|CalendarYearDesc|CalendarQtrID|CalendarQtrDesc|CalendarMonthID|CalendarMonthDesc|CalendarWeekID|CalendarWeekDesc|DayOfWeekNum|DayOfWeekDesc|FiscalYearID|FiscalYearDesc|FiscalQtrID|FiscalQtrDesc|HolidayFlag|\n",
      "+---------+----------+----------------+--------------+----------------+-------------+---------------+---------------+-----------------+--------------+----------------+------------+-------------+------------+--------------+-----------+-------------+-----------+\n",
      "| 19500101|1950-01-01| January 1, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           7|       Sunday|        1950|          1950|      19503|      1950 Q3|       true|\n",
      "| 19500102|1950-01-02| January 2, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           1|       Monday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500103|1950-01-03| January 3, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           2|      Tuesday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500104|1950-01-04| January 4, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           3|    Wednesday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500105|1950-01-05| January 5, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           4|     Thursday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500106|1950-01-06| January 6, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           5|       Friday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500107|1950-01-07| January 7, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           6|     Saturday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500108|1950-01-08| January 8, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19502|         1950-W2|           7|       Sunday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500109|1950-01-09| January 9, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19502|         1950-W2|           1|       Monday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500110|1950-01-10|January 10, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19502|         1950-W2|           2|      Tuesday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "+---------+----------+----------------+--------------+----------------+-------------+---------------+---------------+-----------------+--------------+----------------+------------+-------------+------------+--------------+-----------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Date.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SK_DateID: integer (nullable = true)\n",
      " |-- DateValue: string (nullable = true)\n",
      " |-- DateDesc: string (nullable = true)\n",
      " |-- CalendarYearID: integer (nullable = true)\n",
      " |-- CalendarYearDesc: string (nullable = true)\n",
      " |-- CalendarQtrID: integer (nullable = true)\n",
      " |-- CalendarQtrDesc: string (nullable = true)\n",
      " |-- CalendarMonthID: integer (nullable = true)\n",
      " |-- CalendarMonthDesc: string (nullable = true)\n",
      " |-- CalendarWeekID: integer (nullable = true)\n",
      " |-- CalendarWeekDesc: string (nullable = true)\n",
      " |-- DayOfWeekNum: integer (nullable = true)\n",
      " |-- DayOfWeekDesc: string (nullable = true)\n",
      " |-- FiscalYearID: integer (nullable = true)\n",
      " |-- FiscalYearDesc: string (nullable = true)\n",
      " |-- FiscalQtrID: integer (nullable = true)\n",
      " |-- FiscalQtrDesc: string (nullable = true)\n",
      " |-- HolidayFlag: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_Date.createOrReplaceTempView(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dimDate = spark.sql(\"\\\n",
    "                       Select SK_DateID,\\\n",
    "                           Cast(DateValue as date),\\\n",
    "                           DateDesc,\\\n",
    "                           CalendarYearID,\\\n",
    "                           CalendarYearDesc,\\\n",
    "                           CalendarQtrID,\\\n",
    "                           CalendarQtrDesc,\\\n",
    "                           CalendarMonthID,\\\n",
    "                           CalendarMonthDesc,\\\n",
    "                           CalendarWeekID,\\\n",
    "                           CalendarWeekDesc,\\\n",
    "                           DayOfWeekNum,\\\n",
    "                           DayOfWeekDesc,\\\n",
    "                           FiscalYearID,\\\n",
    "                           FiscalYearDesc,\\\n",
    "                           FiscalQtrID,\\\n",
    "                           FiscalQtrDesc,\\\n",
    "                           HolidayFlag\\\n",
    "                       From date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+--------------+----------------+-------------+---------------+---------------+-----------------+--------------+----------------+------------+-------------+------------+--------------+-----------+-------------+-----------+\n",
      "|SK_DateID| DateValue|        DateDesc|CalendarYearID|CalendarYearDesc|CalendarQtrID|CalendarQtrDesc|CalendarMonthID|CalendarMonthDesc|CalendarWeekID|CalendarWeekDesc|DayOfWeekNum|DayOfWeekDesc|FiscalYearID|FiscalYearDesc|FiscalQtrID|FiscalQtrDesc|HolidayFlag|\n",
      "+---------+----------+----------------+--------------+----------------+-------------+---------------+---------------+-----------------+--------------+----------------+------------+-------------+------------+--------------+-----------+-------------+-----------+\n",
      "| 19500101|1950-01-01| January 1, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           7|       Sunday|        1950|          1950|      19503|      1950 Q3|       true|\n",
      "| 19500102|1950-01-02| January 2, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           1|       Monday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500103|1950-01-03| January 3, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           2|      Tuesday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500104|1950-01-04| January 4, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           3|    Wednesday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500105|1950-01-05| January 5, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           4|     Thursday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500106|1950-01-06| January 6, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           5|       Friday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500107|1950-01-07| January 7, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19501|         1950-W1|           6|     Saturday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500108|1950-01-08| January 8, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19502|         1950-W2|           7|       Sunday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500109|1950-01-09| January 9, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19502|         1950-W2|           1|       Monday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "| 19500110|1950-01-10|January 10, 1950|          1950|            1950|        19501|        1950 Q1|          19501|     1950 January|         19502|         1950-W2|           2|      Tuesday|        1950|          1950|      19503|      1950 Q3|      false|\n",
      "+---------+----------+----------------+--------------+----------------+-------------+---------------+---------------+-----------------+--------------+----------------+------------+-------------+------------+--------------+-----------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimDate.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SK_DateID: integer (nullable = true)\n",
      " |-- DateValue: date (nullable = true)\n",
      " |-- DateDesc: string (nullable = true)\n",
      " |-- CalendarYearID: integer (nullable = true)\n",
      " |-- CalendarYearDesc: string (nullable = true)\n",
      " |-- CalendarQtrID: integer (nullable = true)\n",
      " |-- CalendarQtrDesc: string (nullable = true)\n",
      " |-- CalendarMonthID: integer (nullable = true)\n",
      " |-- CalendarMonthDesc: string (nullable = true)\n",
      " |-- CalendarWeekID: integer (nullable = true)\n",
      " |-- CalendarWeekDesc: string (nullable = true)\n",
      " |-- DayOfWeekNum: integer (nullable = true)\n",
      " |-- DayOfWeekDesc: string (nullable = true)\n",
      " |-- FiscalYearID: integer (nullable = true)\n",
      " |-- FiscalYearDesc: string (nullable = true)\n",
      " |-- FiscalQtrID: integer (nullable = true)\n",
      " |-- FiscalQtrDesc: string (nullable = true)\n",
      " |-- HolidayFlag: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimDate.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "schema_CashTrans = StructType([\n",
    "    StructField(\"CDC_FLAG\", StringType(), False),\n",
    "    StructField(\"CDC_DSN\", IntegerType(), False),\n",
    "    StructField(\"CT_CA_ID\", IntegerType(), False),\n",
    "    StructField(\"CT_DTS\", TimestampType(), False),\n",
    "    StructField(\"CT_AMT\", FloatType(), False),\n",
    "    StructField(\"CT_NAME\", StringType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_CashTrans = spark.read\\\n",
    "            .format(\"csv\")\\\n",
    "            .schema(schema_CashTrans)\\\n",
    "            .option(\"header\", \"false\")\\\n",
    "            .option(\"sep\", \"|\")\\\n",
    "            .load(\"./Dataset/Batch2/CashTransaction.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-------------------+----------+--------------------+\n",
      "|CDC_FLAG|CDC_DSN|CT_CA_ID|             CT_DTS|    CT_AMT|             CT_NAME|\n",
      "+--------+-------+--------+-------------------+----------+--------------------+\n",
      "|       I|4937695|    6507|2017-07-08 10:16:09|   5519.45|AYJRCJpzLBMJUWKjS...|\n",
      "|       I|4938687|    1571|2017-07-08 15:07:22| 623871.06|jPmEvxgxaeaq Uxqu...|\n",
      "|       I|4938975|   11708|2017-07-08 17:55:33|   8712.61|BIOgCYoEPlRuRUiMG...|\n",
      "|       I|4940035|   12403|2017-07-08 22:55:52|-516203.06|          GO ERHHSVO|\n",
      "|       I|4941475|    4189|2017-07-08 21:37:17|  -3084.95|FIgutPGqjffXeBwvY...|\n",
      "|       I|4941627|    4212|2017-07-08 04:46:55|-216073.48|mTyTAMFpoVUAuNfxs...|\n",
      "|       I|4942163|    6390|2017-07-08 14:43:48| -58952.78|GAuMSSixIeaqGjZZL...|\n",
      "|       I|4942839|    9836|2017-07-08 19:28:33|   4761.51|         sqTyZKkSGVG|\n",
      "|       I|4943923|    5689|2017-07-08 05:35:45|  -3700.86|fdMCOdoGxgfVCMpgu...|\n",
      "|       I|4944143|    5689|2017-07-08 07:08:58|   8300.37|RfQEMlybsWPp YfrGzVm|\n",
      "+--------+-------+--------+-------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_CashTrans.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_CashTrans.createOrReplaceTempView(\"cashTrans\")\n",
    "dimDate.createOrReplaceTempView(\"dimDate_tbl\")\n",
    "dimAccount.createOrReplaceTempView(\"dimAccount_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "factCashBalances = spark.sql(\"\\\n",
    "                       Select CustomerID,\\\n",
    "                           AccountID,\\\n",
    "                           SK_DateID,\\\n",
    "                           sum(CT_AMT) as Cash,\\\n",
    "                           CAST('1' as INT) as BatchID\\\n",
    "                       From cashTrans join dimAccount_tbl as ac on (CT_CA_ID =ac.AccountID)\\\n",
    "                       join dimDate_tbl as dt on dt.DateValue = Date(CT_DTS)\\\n",
    "                       Group by AccountID, CustomerID, SK_DateID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+------------------+-------+\n",
      "|CustomerID|AccountID|SK_DateID|              Cash|BatchID|\n",
      "+----------+---------+---------+------------------+-------+\n",
      "|      1337|     2562| 20170708|    -87205.7421875|      1|\n",
      "|      1514|     9587| 20170708|1647.3900146484375|      1|\n",
      "|       383|    11259| 20170708|-2605.860107421875|      1|\n",
      "|      4858|     9618| 20170708| -3108.56005859375|      1|\n",
      "|      1356|     3627| 20170708|   8159.0498046875|      1|\n",
      "+----------+---------+---------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factCashBalances.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dimAccount.write.parquet(\"dimAccount.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dimDate.write.parquet(\"dimDate.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dimCustomer.write.parquet(\"dimCustomer.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "factCashBalances.write.parquet(\"factCashBalances.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
